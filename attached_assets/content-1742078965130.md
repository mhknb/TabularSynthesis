[Skip to content](https://towardsdatascience.com/how-to-generate-tabular-data-using-ctgans-9386e45836a6/#wp--skip-link--target)

[Data Science](https://towardsdatascience.com/category/data-science/)

# How to Generate Tabular Data Using CTGANs

An in-depth explanation of how CTGANs work

[Diego Unzueta](https://towardsdatascience.com/author/diegounzuetaruedas/)

Nov 9, 2021

10 min read

Share

### [Hands-on Tutorials](https://towardsdatascience.com/tagged/hands-on-tutorials), Practical Machine Learning

![Image by Author](https://towardsdatascience.com/wp-content/uploads/2021/11/135XVBGd84xVIMIwAW-yEBA.png)Image by Author

The purpose of this article is to fill the gap in the internet for a good explanation of how Conditional Tabular GANs work. Tabular data generation is a growing field of research; the CTGANs paper has become the foundation of many other machine learning architectures that today constitute the state of the art of this field of research.

## Why Tabular Data Generation?

In my previous two articles I explored how to generate image data using [Generative Adversarial](https://towardsdatascience.com/tag/generative-adversarial/ "Generative Adversarial") Networks (GANs). In a way, these have been a build-up for this article. Although image data makes for pretty visualizations, in practice, the most common kind of data used in industry and literature is tabular data. Tabular data is structured and is often easier to deal with when training machine learning models. However, when it comes to generating tabular data, to make a well-performing model it can actually complicate things a lot.

The goal of this article is to go through how CTGANs work. To do so I’ll first give a small explanation of GANs and tabular data. Then I will go through the architecture described in the original CTGANs paper. Finally, I will go through an example implementation using Python.

## Recap on GANs

![Image by Author](https://towardsdatascience.com/wp-content/uploads/2021/11/1392GXZkvTW1Wjk1dgYLRIQ.png)Image by Author

GANs fall in the branch of deep learning generator networks. This is a supervised learning problem, where we have a set of real data, and we want to augment this dataset through the use of a generator. GANs learn to generate samples, this is fundamentally different from learning distributions (check out my article on **differentiable generator networks** for more details).

GANs consist of two neural networks, the generator, and the discriminator. The generator generates new data, whilst the discriminator attempts to correctly classify the real and fake data.

The two networks have adversarial goals in training. The discriminator attempts to maximize its classification accuracy (correctly identifying what images come from the generator), whilst the generator’s goal is to fool the discriminator. At the end of learning, the generator should be able to produce images that look a lot like the real dataset, so much so that they may fool humans into thinking they are real.

## Tabular Data

As I mentioned earlier, tabular data is structured. Unstructured data (like text or images) is a lot harder for [Machine Learning](https://towardsdatascience.com/tag/machine-learning/ "Machine Learning") models to learn from. In most cases, dealing with image data is a lot more complicated. However, when generating tabular data, you will see the algorithms can get very complex very quickly.

### Kind of tabular data

Tabular data can either be numerical or categorial.

![Image by Author](https://towardsdatascience.com/wp-content/uploads/2021/11/1_kWcU4NVAxHTNFqmJanmmw.png)Image by Author

Numerical data can either be continuous of discrete. Continuous data has no limit in resolution. Weight can be measured in tonnes, kg, g, mg, etc. Discrete variables have unique numerical values. An example is the number of children in your family. As for categorical, there is ordinal data (categorical data with an order such as the day of the week), and nominal data (categorical data with no order).

In literature, discrete, ordinal, and nominal are all grouped together and called discrete data. This is because when training a neural network you will not give if the days of the week as a vector {"Monday", "Tuesday" …}. Instead, you might give it a vector as {0, 1 …}. So this means we can treat discrete and categorical data as the same.

### Problem setting

A tabular dataset _T_ can be said to contain _Nd_ discrete columns and _Nc_ continuous columns. The goal of tabular data generation is to train a generator _G_ to learn to generate a synthetic dataset _Tsynth_ from _T._

In literature there are two key foundational papers that explore the generation of tabular data, these are [TGANs by Lei Xu et al.](https://arxiv.org/abs/1811.11264) and [CTGANs by Lei Xu et al.](https://arxiv.org/pdf/1907.00503.pdf) In this article, I will focus on CTGANs, which is the architecture that has taken off in the industry and has been pivotal in the growth of the tabular data generation research field.

## **CTGANs –** Proposed Adaptations

To achieve the task of tabular data generation, one could train a vanilla GAN, however, there are two adaptations that CTGANs proposes that attempt to tackle two issues with GANs when applied to tabular data.

### A representative normalization of continuous data

The first problem CTGANs attempt to solve is to do with normalizing continuous data.

Let’s first look at how discrete data can be represented.

Discrete data is easy to represent, as this one can be one-hot encoded. One-hot encoding is simply the process of categorizing every category in a discrete variable into its own dimension. In the example given earlier for the weekdays, instead of having a vector containing the day of the working week, after one-hot encoding, we have 5 columns, one for each day of the week, with binary indications of class membership.

![Image by Author](https://towardsdatascience.com/wp-content/uploads/2021/11/1kMg2Rv6c4H3JrRaWNsH7qw.png)Image by Author

Above, the first vector {1,0,0,0,0} indicates a Monday. The second vector {0,1,0,0,0} represents a Tuesday and so on. One hot encoding gives us a normalized way to represent discrete variables well.

However, when it comes to continuous data, it is difficult to express all the information carried by the continuous variable. Let’s look at an example:

![Image by Author](https://towardsdatascience.com/wp-content/uploads/2021/11/1yemgVBrIWAj4b38g074ecA.png)Image by Author

Say we have a continuous variable like the one above (distribution in blue) and we want to represent our sample (in red). As you can see, the distribution is quite complex, it has multiple modes. Therefore by simply giving the model the value of the continuous variable at our sample, we may lose some information, such as what mode the sample belongs to, and its importance within that mode.

The authors propose a solution that they call **mode-specific normalization** which transforms the continuous variable into a vector containing the information we described above.

Mode-specific normalization works by first fitting a VGM (variational Gaussian mixture model) to each continuous variable. A gaussian mixture model simply tries to find the best k Gaussians to represent the data through expectation maximization. VGMs can decide what’s the best number of Gaussians (k) to fit onto the data through a weights threshold.

![Image by Lei Xu et al. Modeling Tabular Data using Conditional GAN [1]](https://towardsdatascience.com/wp-content/uploads/2021/11/1bF2Whe7uW-kqETdjl1aOqg.png)Image by [Lei Xu et al. Modeling Tabular Data using Conditional GAN](https://arxiv.org/pdf/1907.00503.pdf) \[1\]

Once we have found the k Gaussian distributions that best model our continuous variable, we can evaluate the sample at each of the Gaussians. From there, we can decide what distribution the sample belongs to (this is represented by β. Finally, we can represent the value of the sample within its distribution (how important that sample is in its gaussian) using the α term.

In the example from the paper, the VGM finds 3 Gaussians to represent the distribution of the continuous variable (k=3). The sample c (in red) is encoded as a β vector {0,0,1}, and an α vector using the equation shown above.

And that’s it, to solve the normalization problem, instead of giving the model the continuous variable, we give it α and β.

### A fair sampling of discrete data

The second issue with GANs and tabular data that the authors attempt to solve has to do with random sampling and discrete data.

When training the generator of a GAN, the input noise is drawn from a prior distribution (usually a multi-variate gaussian). Sampling in this way for discrete variables may miss information about their distribution. It would be useful for the model to somehow include information from the discrete variables as input, and for it to learn to map that input accordingly to the desired output. The solution the paper proposes consists of three key elements: c **onditional vector, generator loss, training-by-sampling.**

In order to force the generator to generate samples with similar distributions in discrete variables as the training data, some information about the desired discrete variables must be contained on the input aside from the random noise. So they choose to include a **conditional vector.**

The **conditional vector** allows us to force the generator to generate a sample from a chosen category. The conditional vector contains all the discrete columns, one-hot encoded, where all the values are set to zero except for one category in one discrete column (the condition we want the generated sample to fulfil). The condition is chosen through **training-by-sampling**.

CTGANs **training-by-sampling** allows us to sample the conditions to generate the **conditional vectors** such that the distributions generated by the generator match the distributions of the discrete variables in the training data. Training by sampling is done as follows:

- First, a random discrete column is selected
- From this discrete column, a category is selected based on a probability mass function constructed from the frequencies of occurrence of each category in that discrete column.
- The condition is transformed to the conditional vector and used as input to the generator

The final adaptation is to the **generator loss.** The generator loss is adapted to force the generator to generate a sample with this condition. They do this by adding the cross-entropy between the conditional vector and the generated sample to the loss term. This forces the produced samples to abide by the condition.

## Application Example

For this example, I used the [Titanic dataset](https://www.openml.org/d/40945)\[2\]. The goal is to generate data that looks as realistic as possible.

![Image by Author](https://towardsdatascience.com/wp-content/uploads/2021/11/11HSjNBRdYJAQbKs-IIXWzA.png)Image by Author

On the image above, to the left is the real distribution of passengers who died and survived on the titanic from the dataset. To the right is the generated distribution. As you can see CTGAN learns to generate distributions similar to those in the training data.

**Problems with CTGANs**

Although CTGANs can learn the distributions of the training data, sometimes they can miss correlations between these and other important aspects.

![Image by Author](https://towardsdatascience.com/wp-content/uploads/2021/11/1TxRGyhEu50sFKuZnJBDuqw.png)Image by Author

All the images to the left correspond to the distribution of the real data, the images to the right correspond to distributions of the fake data. You can see that the generator misses key relationships in the training data. For example, in the real data, you can see if you were a woman, you were much more likely to survive in the titanic. This information is not captured by the synthetic data generator. Another big problem with the generator is that it is generating samples with negative age!

Despite all the theory, CTGANs on their own are definitely not perfect. Although they captured well the general shape of the distributions of each variable, they failed to capture a lot of the information shared between them.

## **Conclusion**

In this article, I explained a pivotal method to generate tabular data. Conditional Tabular GANs can be difficult to understand but present a very beautiful solution to some of the biggest problems in tabular data generation.

At the end of the article, I quickly show the results of the vanilla CTGANs algorithm applied to an example dataset. CTGANs are not perfect, but they can be improved in a number of ways. In future articles, I will discuss other architectures that stem from CTGANs, and how these combat some of the flaws we found in this article.

## Support me

Hopefully this helped you, if you enjoyed it you can **[follow me!](https://medium.com/@diegounzuetaruedas)**

You can also become a **[medium member](https://diegounzuetaruedas.medium.com/membership))** using my referral link, get access to all my articles and more: [https://diegounzuetaruedas.medium.com/membership](https://diegounzuetaruedas.medium.com/membership)

## Other articles you might enjoy

[Differentiable Generator Networks: an Introduction](https://towardsdatascience.com/differentiable-generator-networks-an-introduction-5a9650a24823)

[Fourier Transforms: An Intuitive Visualisation](https://towardsdatascience.com/fourier-transforms-an-intuitive-visualisation-ba186c7380ee)

## References

\[1\] Xu, L. and Veeramachaneni, K., 2018. Synthesizing Tabular Data using Generative Adversarial Networks. _Cornell University_.

\[2\] Dataset: Titanic – by Joaquin Vanschoren, Author: Frank E. Harrell Jr., Thomas Cason— [https://www.openml.org/d/40945](https://www.openml.org/d/40945)

* * *

Written By

Diego Unzueta

[See all from Diego Unzueta](https://towardsdatascience.com/author/diegounzuetaruedas/)

Topics:

[Data Science](https://towardsdatascience.com/tag/data-science/), [Editors Pick](https://towardsdatascience.com/tag/editors-pick/), [Generative Adversarial](https://towardsdatascience.com/tag/generative-adversarial/), [Hands On Tutorials](https://towardsdatascience.com/tag/hands-on-tutorials/), [Machine Learning](https://towardsdatascience.com/tag/machine-learning/)

Share this article:

- [Share on Facebook](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-generate-tabular-data-using-ctgans-9386e45836a6%2F&title=How%20to%20Generate%20Tabular%20Data%20Using%20CTGANs)
- [Share on LinkedIn](https://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-generate-tabular-data-using-ctgans-9386e45836a6%2F&title=How%20to%20Generate%20Tabular%20Data%20Using%20CTGANs)
- [Share on X](https://x.com/share?url=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-generate-tabular-data-using-ctgans-9386e45836a6%2F&text=How%20to%20Generate%20Tabular%20Data%20Using%20CTGANs)

## Related Articles

- ![](https://towardsdatascience.com/wp-content/uploads/2024/08/0c09RmbCCpfjAbSMq.png)





## [Implementing Convolutional Neural Networks in TensorFlow](https://towardsdatascience.com/implementing-convolutional-neural-networks-in-tensorflow-bc1c4f00bd34/)

[Artificial Intelligence](https://towardsdatascience.com/category/artificial-intelligence/)





Step-by-step code guide to building a Convolutional Neural Network









[Shreya Rao](https://towardsdatascience.com/author/shreya-rao/)





August 20, 2024




6 min read

- ![Photo by Krista Mangulsone on Unsplash](https://towardsdatascience.com/wp-content/uploads/2024/08/0GyVVTbgotH-DhGPH-scaled.jpg)





## [How to Forecast Hierarchical Time Series](https://towardsdatascience.com/how-to-forecast-hierarchical-time-series-75f223f79793/)

[Artificial Intelligence](https://towardsdatascience.com/category/artificial-intelligence/)





A beginner’s guide to forecast reconciliation









[Dr. Robert Kübler](https://towardsdatascience.com/author/dr-robert-kuebler/)





August 20, 2024




13 min read

- ![Photo by davisuko on Unsplash](https://towardsdatascience.com/wp-content/uploads/2024/08/1bAABgtZtAIG5YW1oEjW3pA-scaled.jpeg)





## [Hands-on Time Series Anomaly Detection using Autoencoders, with Python](https://towardsdatascience.com/hands-on-time-series-anomaly-detection-using-autoencoders-with-python-7cd893bbc122/)

[Data Science](https://towardsdatascience.com/category/data-science/)





Here’s how to use Autoencoders to detect signals with anomalies in a few lines of…









[Piero Paialunga](https://towardsdatascience.com/author/piero-paialunga/)





August 21, 2024




12 min read

- ![Image from Canva.](https://towardsdatascience.com/wp-content/uploads/2024/08/1UAA9jQVdqMXnwzYiz8Q53Q.png)





## [3 AI Use Cases (That Are Not a Chatbot)](https://towardsdatascience.com/3-ai-use-cases-that-are-not-a-chatbot-f4f328a2707a/)

[Machine Learning](https://towardsdatascience.com/category/artificial-intelligence/machine-learning/)





Feature engineering, structuring unstructured data, and lead scoring









[Shaw Talebi](https://towardsdatascience.com/author/shawhin/)





August 21, 2024




7 min read

- ## [Solving a Constrained Project Scheduling Problem with Quantum Annealing](https://towardsdatascience.com/solving-a-constrained-project-scheduling-problem-with-quantum-annealing-d0640e657a3b/)

[Data Science](https://towardsdatascience.com/category/data-science/)





Solving the resource constrained project scheduling problem (RCPSP) with D-Wave’s hybrid constrained quadratic model (CQM)









[Luis Fernando PÉREZ ARMAS, Ph.D.](https://towardsdatascience.com/author/luisfernandopa1212/)





August 20, 2024




29 min read

- ![](https://towardsdatascience.com/wp-content/uploads/2023/02/1VEUgT5T4absnTqBMOEuNig.png)





## [Back To Basics, Part Uno: Linear Regression and Cost Function](https://towardsdatascience.com/back-to-basics-part-uno-linear-regression-cost-function-and-gradient-descent-590dcb3eee46/)

[Data Science](https://towardsdatascience.com/category/data-science/)





An illustrated guide on essential machine learning concepts









[Shreya Rao](https://towardsdatascience.com/author/shreya-rao/)





February 3, 2023




6 min read

- ![](https://towardsdatascience.com/wp-content/uploads/2024/08/1kM8tfYcdaoccB1HX71YDig.png)





## [Must-Know in Statistics: The Bivariate Normal Projection Explained](https://towardsdatascience.com/must-know-in-statistics-the-bivariate-normal-projection-explained-ace7b2f70b5b/)

[Data Science](https://towardsdatascience.com/category/data-science/)





Derivation and practical examples of this powerful concept









[Luigi Battistoni](https://towardsdatascience.com/author/lu-battistoni/)





August 14, 2024




7 min read

- ![Photo by Jess Bailey on Unsplash](https://towardsdatascience.com/wp-content/uploads/2022/09/11tHmNYFaWWtWG5I7bNeN6g-scaled.jpeg)





## [How to Make the Most of Your Experience as a TDS Author](https://towardsdatascience.com/how-to-make-the-most-of-your-experience-as-a-tds-author-b1e056be63f1/)

[Data Science](https://towardsdatascience.com/category/data-science/)





A quick guide to our resources and FAQ









[TDS Editors](https://towardsdatascience.com/author/towardsdatascience/)





September 13, 2022




4 min read

- ![Photo by Alex Geerts on Unsplash](https://towardsdatascience.com/wp-content/uploads/2020/11/0BF38u2sw4WQdaMLS-scaled.jpg)





## [Our Columns](https://towardsdatascience.com/our-columns-53501f74c86d/)

[Data Science](https://towardsdatascience.com/category/data-science/)





Columns on TDS are carefully curated collections of posts on a particular idea or category…









[TDS Editors](https://towardsdatascience.com/author/towardsdatascience/)





November 14, 2020




4 min read


td.doubleclick.net

# td.doubleclick.net is blocked

This page has been blocked by an extension

- Try disabling your extensions.

ERR\_BLOCKED\_BY\_CLIENT

Reload


This page has been blocked by an extension

![](<Base64-Image-Removed>)![](<Base64-Image-Removed>)

Some areas of this page may shift around if you resize the browser window. Be sure to check heading and document order.

![Company Logo](https://cdn.cookielaw.org/logos/static/ot_company_logo.png)

## Privacy Preference Center

When you visit any website, it may store or retrieve information on your browser, mostly in the form of cookies. This information might be about you, your preferences or your device and is mostly used to make the site work as you expect it to. The information does not usually directly identify you, but it can give you a more personalized web experience. Because we respect your right to privacy, you can choose not to allow some types of cookies. Click on the different category headings to find out more and change our default settings. However, blocking some types of cookies may impact your experience of the site and the services we are able to offer.


[More information](https://cookiepedia.co.uk/giving-consent-to-cookies)

Allow All

### Manage Consent Preferences

#### Functional Cookies

Functional CookiesActive

These cookies enable the website to provide enhanced functionality and personalisation. They may be set by us or by third party providers whose services we have added to our pages. If you do not allow these cookies then some or all of these services may not function properly.

#### Strictly Necessary Cookies

Always Active

These cookies are necessary for the website to function and cannot be switched off in our systems. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can set your browser to block or alert you about these cookies, but some parts of the site will not then work. These cookies do not store any personally identifiable information.

#### Performance Cookies

Performance CookiesActive

These cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site. They help us to know which pages are the most and least popular and see how visitors move around the site. All information these cookies collect is aggregated and therefore anonymous. If you do not allow these cookies we will not know when you have visited our site, and will not be able to monitor its performance.

#### Targeting Cookies

Targeting CookiesActive

These cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. They do not store directly personal information, but are based on uniquely identifying your browser and internet device. If you do not allow these cookies, you will experience less targeted advertising.

Back Button

### Cookie List

Search Icon

Filter Icon

Clear

checkbox labellabel

ApplyCancel

ConsentLeg.Interest

checkbox labellabel

checkbox labellabel

checkbox labellabel

Reject AllConfirm My Choices

[![Powered by Onetrust](https://cdn.cookielaw.org/logos/static/powered_by_logo.svg)](https://www.onetrust.com/products/cookie-consent/)